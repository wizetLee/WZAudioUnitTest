//
//  WZMultichannelMixerEngine.m
//  WZWeather
//
//  Created by admin on 4/1/18.
//  Copyright Â© 2018å¹´ WZ. All rights reserved.
//

#import "WZMultichannelMixerEngine.h"

#define SAMPLERATE 44100.0//[[AVAudioSession sharedInstance] sampleRate]

static const int BusCount = 2;

typedef struct {
    AudioStreamBasicDescription asbd;   //ID
    Float32 *data;                      //å®é™…æ•°æ®
    UInt32 numFrames;                   //å¸§æ•°
    UInt32 sampleNum;                   //æ ·æœ¬å·
} SoundBuffer, *SoundBufferPtr;


@interface WZMultichannelMixerEngine()
{
    AUGraph graph;                          //graph
    AudioUnit mixerUnit;                    //Mixing
    AudioUnit outputUnit;                   //I/O
    AudioUnit effectUnit;                   //Effect
    
    SoundBuffer soundBuffer[BusCount];      //ç»“æ„ä½“æ•°ç»„
}

@end

/**
 è‹¥å¹²ä¸ªinpout bus --->  mixer  ---> effect ----> io
 */
@implementation WZMultichannelMixerEngine


- (instancetype)init
{
    self = [super init];
    if (self) {
        
        memset(&soundBuffer, 0, sizeof(soundBuffer));
        
//        [self configFiles];
////        [self performSelectorInBackground:@selector(configFiles) withObject:nil];
//        [self configGraph];
        
    }
    return self;
}

- (void)configFiles {
    //PCM Format
    AVAudioFormat *clientFormat = [[AVAudioFormat alloc] initWithCommonFormat:AVAudioPCMFormatFloat32 sampleRate:SAMPLERATE channels:1 interleaved:true];
    NSArray <NSURL *>* urlArr = @[
                                  [NSURL fileURLWithPath:[[NSBundle mainBundle] pathForResource:@"å°ä¸‘é±¼" ofType:@"mp3"]],
                                  [NSURL fileURLWithPath:[[NSBundle mainBundle] pathForResource:@"æ•¢ä¸æ•¢" ofType:@"mp3"] ]
//                                  [NSURL fileURLWithPath:[[NSBundle mainBundle] pathForResource:@"DrumsMonoSTP" ofType:@"aif"]],
//                                  [NSURL fileURLWithPath:[[NSBundle mainBundle] pathForResource:@"GuitarMonoSTP" ofType:@"aif"] ]
                                  ];
    
    //bus Count
    for (int i = 0; i < BusCount; i++) {
        ExtAudioFileRef extAFRef = NULL;
        //è·å¾—å¥æŸ„
        
        CheckError(ExtAudioFileOpenURL((__bridge CFURLRef)urlArr[i], &extAFRef), "ExtAudioFileOpenURL");
        //è·å–æ ¼å¼
        AudioStreamBasicDescription ASBD = {0};
        UInt32 ASBDSize = sizeof(AudioStreamBasicDescription);
        CheckError(ExtAudioFileGetProperty(extAFRef, kExtAudioFileProperty_FileDataFormat, &ASBDSize, &ASBD), "kExtAudioFileProperty_FileDataFormat");
        
//ä¿éšœæ ¼å¼ï¼šå–å¾—æ–‡ä»¶çš„æ ¼å¼å¯é€šè¿‡FormatIDæŸ¥çœ‹æ•°æ®ç±»å‹
    /**
        å…³äºï¼škExtAudioFileProperty_ClientDataFormat
        ï¼ˆYou must set this in order to encode or decode a non-PCM file data format.ï¼‰
        å¦‚æœä½¿ç”¨åˆ°éPCMæ•°æ®æ ¼å¼çš„æ–‡ä»¶ï¼Œå¿…é¡»é€šè¿‡æ­¤é”®ä¿®æ”¹æ•°æ®æ ¼å¼
     */
        CheckError(ExtAudioFileSetProperty(extAFRef, kExtAudioFileProperty_ClientDataFormat, ASBDSize, clientFormat.streamDescription), "ClientDataFormat");
        
        //è·å–æ–‡ä»¶å¸§æ•°
        UInt64 numberOfFramesInFile = 0;
        UInt32 ioPropertyDataSize = sizeof(numberOfFramesInFile);
        CheckError(ExtAudioFileGetProperty(extAFRef, kExtAudioFileProperty_FileLengthFrames, &ioPropertyDataSize, &numberOfFramesInFile), "ClientDataFormat");
        
        //åŒ¹é…é€Ÿç‡
        double rateRatie = SAMPLERATE / ASBD.mSampleRate;
        numberOfFramesInFile = numberOfFramesInFile * rateRatie;//å¸§ç‡è½¬æ¢æœ€ç»ˆå¾—åˆ°çš„å¸§æ•° setPro
        
        ///buffer éƒ¨åˆ† BusCount
        //buffer åˆ›å»º ä¹‹åé€šè¿‡ä½¿ç”¨audioUnitRender å°† AudioBufferList çš„æ•°æ®é€šè¿‡audio unit pullå‡ºå»
        SoundBuffer *bufferStr = &soundBuffer[i];
        (*bufferStr).numFrames = (UInt32)numberOfFramesInFile;
        (*bufferStr).asbd = *clientFormat.streamDescription;
        UInt32 samples = (UInt32)numberOfFramesInFile * (*bufferStr).asbd.mChannelsPerFrame;//é€šé“æ•° * å¸§æ•°
        (*bufferStr).data = (Float32 *)calloc(samples, sizeof(Float32));//åˆ›å»ºå¯¹åº”å¤§çš„ç©ºé—´
        (*bufferStr).sampleNum = 0;
        
        //è¯»å–æ•°æ®åˆ°ABLä¸­
        AudioBufferList ABL = {};
        ABL.mNumberBuffers = 1;
        ABL.mBuffers[0].mNumberChannels = 1;
        ABL.mBuffers[0].mDataByteSize = samples * sizeof(UInt32);//å­—èŠ‚ 2^8
#warning å‡ºé”™åœ¨è¿™é‡ŒğŸ˜“ åº”è¯¥å…³è”ä¸Šè¿™ä»½buffer
//        ABL.mBuffers[0].mData = (Float32 *)calloc(samples, sizeof(Float32));
        ABL.mBuffers[0].mData = soundBuffer[i].data;
        
//å¤§æ–‡ä»¶å¡é¡¿
        //åŒæ­¥æŒ‰é¡ºåºæŠŠéŸ³é¢‘æ•°æ®ä»æ–‡ä»¶ä¸­è¯»å–åˆ°åˆ›å»ºçš„bufferä¸­
        UInt32 numPackets = (UInt32)numberOfFramesInFile;
        if (CheckError(ExtAudioFileRead(extAFRef, &numPackets, &ABL), "ExtAudioFileRead") != noErr) {
            free(soundBuffer[i].data);
            soundBuffer[i].data = 0;
        }
        CheckError(ExtAudioFileDispose(extAFRef), "ExtAudioFileDispose");
    }
}

- (void)configGraph {
    
    if (CheckError(NewAUGraph(&graph), "NewAUGraph(&auGraph)") != noErr) {
        return;
    };
    
    AudioComponentDescription ACD = {0};
    ACD.componentManufacturer     = kAudioUnitManufacturer_Apple;
    ACD.componentFlags            = 0;
    ACD.componentFlagsMask        = 0;
    
    //node
    AUNode outputNode, mixerNode, effectNode;
//get node
    //IO
    ACD.componentType             = kAudioUnitType_Output;
    ACD.componentSubType          = kAudioUnitSubType_RemoteIO;
    CheckError(AUGraphAddNode(graph, &ACD, &outputNode), "outputNode");
    
    //Effect
//    ACD.componentType             = kAudioUnitType_Effect;
//    ACD.componentSubType          = kAudioUnitSubType_SampleDelay;
//    CheckError(AUGraphAddNode(graph, &ACD, &effectNode), "effectNode");
    
    //Mixing
    ACD.componentType             = kAudioUnitType_Mixer;
    ACD.componentSubType          = kAudioUnitSubType_MultiChannelMixer;//å¤šé€šé“
    CheckError(AUGraphAddNode(graph, &ACD, &mixerNode), "mixerNode");

//    AUGraphConnectNodeInput(graph, effectNode, 0, mixerNode, 0);
    
    //connect a node's output to a node's input
    AUGraphConnectNodeInput(graph, mixerNode, 0/*source node bus*/, outputNode, 0/*desinatation node element*/);

    //open graph
    CheckError(AUGraphOpen(graph), "graphOpen");

//get unit
    CheckError(AUGraphNodeInfo(graph, mixerNode, NULL, &mixerUnit), "mixerUnit");
//    CheckError(AUGraphNodeInfo(graph, effectNode, NULL, &effectUnit), "effectUnit");
    CheckError(AUGraphNodeInfo(graph, outputNode, NULL, &outputUnit), "outputUnit");
    
//////////////////å±æ€§é…ç½®
 
    //é…ç½®input bus çš„æ•°ç›®
    UInt32 tmpBusCount = BusCount;
    AudioUnitSetProperty(mixerUnit, kAudioUnitProperty_ElementCount, kAudioUnitScope_Input, 0, &tmpBusCount, sizeof(tmpBusCount));
    
    //the format for the graph åˆ¶å®šgraphçš„æ ¼å¼
    AVAudioFormat *format = [[AVAudioFormat alloc] initWithCommonFormat:AVAudioPCMFormatFloat32 sampleRate:SAMPLERATE channels:2 interleaved:false];
    //ä¸º2ä¸ªinputåˆ†å‘å†…å®¹
    for (int i = 0; i < tmpBusCount; i++) {
        AURenderCallbackStruct inputCallBack = {};
        inputCallBack.inputProc = &renderInput;//å¤„ç†
        inputCallBack.inputProcRefCon = soundBuffer;//å¼•ç”¨
        
        //ä¸ºæŒ‡å®šçš„nodeçš„è§¦å‘æŒ‡å®šinput call back è°ƒåº¦ : pull
        CheckError(AUGraphSetNodeInputCallback(graph, mixerNode, i, &inputCallBack), "AUGraphSetNodeInputCallback");
        //ç­‰æ•ˆäº
//        CheckError(AudioUnitSetProperty(mixerUnit, kAudioUnitProperty_SetRenderCallback, kAudioUnitScope_Input, i, &inputCallBack, sizeof(inputCallBack)), "SetRenderCallback");
        
        //è®¾ç½®mixerUnit çš„input bus æ•°æ®æµæ ¼å¼
        CheckError(AudioUnitSetProperty(mixerUnit, kAudioUnitProperty_StreamFormat, kAudioUnitScope_Input, i, format.streamDescription, sizeof(AudioStreamBasicDescription)), "_StreamFormat");
    }
    
    CheckError(AudioUnitSetProperty(mixerUnit, kAudioUnitProperty_StreamFormat, kAudioUnitScope_Output, 0, format.streamDescription, sizeof(AudioStreamBasicDescription)), "_StreamFormat");
    
    //æ ¼å¼ä¼ é€’   IO
     CheckError(AudioUnitSetProperty(outputUnit, kAudioUnitProperty_StreamFormat, kAudioUnitScope_Input, 0, format.streamDescription, sizeof(AudioStreamBasicDescription)), "_StreamFormat");
    //æˆ–è€…
//    CheckError(AudioUnitSetProperty(outputUnit, kAudioUnitProperty_StreamFormat, kAudioUnitScope_Output, 1, format.streamDescription, sizeof(AudioStreamBasicDescription)), "_StreamFormat");
    
    //validate connectionï¼š éªŒè¯é“¾æ¥ä»¥åŠåˆå§‹åŒ–graph
    CheckError(AUGraphInitialize(graph), "AUGraphInitialize");
    
    CAShow(graph);
}


#pragma mark - callBack
static OSStatus renderInput(void * inRefCon,
                    AudioUnitRenderActionFlags *    ioActionFlags,
                    const AudioTimeStamp *            inTimeStamp,
                    UInt32                            inBusNumber,
                    UInt32                            inNumberFrames,
                    AudioBufferList * __nullable    ioData) {
    
    SoundBufferPtr sndbuf = (SoundBufferPtr)inRefCon;       //ä¸¤ä»½ç¼“å­˜
    //æ ¹æ®busè·å¾—å¯¹åº”çš„ä¿¡æ¯
    UInt32 sample = sndbuf[inBusNumber].sampleNum;          //æ ·æœ¬å·
    UInt32 bufSamples = sndbuf[inBusNumber].numFrames;      //æ€»å¸§æ•°
    
    Float32 *inSide = sndbuf[inBusNumber].data;             //æ•°æ®
    
    if (inSide) {
        Float32 *outL = (Float32 *)ioData->mBuffers[0].mData; // å·¦å£°é“æ•°æ®
        Float32 *outR = (Float32 *)ioData->mBuffers[1].mData; // å³å£°é“æ•°æ®
        for (UInt32 i = 0; i < inNumberFrames; ++i) {
            if (1 == inBusNumber) {
                outL[i] = 0;
                outR[i] = inSide[sample];
                ++sample;
            } else {
                outL[i] = inSide[sample];
                outR[i] = 0;
                ++sample;
            }
        }
    }
    
    //å¾ªç¯æ•ˆæœ
    if (sample > bufSamples) {
        sample = 0;
    }
    sndbuf[inBusNumber].sampleNum = sample;//æ›´æ–°æ ·æœ¬ä½ç½®
    
    return noErr;
}


- (BOOL)graphIsRunning {
    Boolean isRunning = false;
    CheckError(AUGraphIsRunning(graph, &isRunning), "AUGraphIsRunning");
    return isRunning;
}

#pragma mark - action
- (void)play {
    [self graphStart];
}

- (void)stop {
    [self graphStop];
}

- (void)rePlay {
    soundBuffer[0].sampleNum = 0;
    soundBuffer[1].sampleNum = 0;
    [self graphStart];
}

//å¯åŠ¨
- (void)graphStart {
    if (![self graphIsRunning]) {
        CheckError(AUGraphStart(graph), "AUGraphStart");//å¼€å§‹pull head node -> sub node -> sub node
    }
}

//åœæ­¢
- (void)graphStop {
    if ([self graphIsRunning]) {
        CheckError(AUGraphStop(graph), "AUGraphStop");//stop pull
    }
}

//æ§åˆ¶mixerUnitæŸä¸ªinput busæ˜¯å¦å¯ç”¨é…ç½®
- (void)enableBusInput:(UInt32)busInputNumber isOn:(AudioUnitParameterValue)isOn {
    CheckError(AudioUnitSetParameter(mixerUnit, kMultiChannelMixerParam_Enable, kAudioUnitScope_Input, busInputNumber, isOn, 0), "kMultiChannelMixerParam_Enable");
}

//æ§åˆ¶mixerUnit input busçš„éŸ³é‡
- (void)setBusInput:(UInt32)busInputNumber volume:(AudioUnitParameterValue)volume {
    CheckError(AudioUnitSetParameter(mixerUnit, kMultiChannelMixerParam_Volume, kAudioUnitScope_Input, busInputNumber, volume, 0), "kMultiChannelMixerParam_Volume");
}

//æ§åˆ¶mixerUnit output busçš„éŸ³é‡
- (void)setOutputBusVolume:(AudioUnitParameterValue)volume {
    CheckError(AudioUnitSetParameter(mixerUnit, kMultiChannelMixerParam_Volume, kAudioUnitScope_Output, 0, volume, 0), "kMultiChannelMixerParam_Volume");
}




@end
